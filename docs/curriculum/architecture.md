# AI Architect Learning System Architecture

## North Star
The 2025 Academy delivers a governed, adaptive learning operating system that turns high-performing builders into executive-level AI architects. Every learner navigates a telemetry-rich environment that:
- Maps business impact pathways before the first lesson.
- Couples micro-concepts with live delivery work, so every hour builds evidence.
- Keeps content current via weekly research ingestion, partner briefs, and frontier lab snapshots.
- Uses companion agents to scaffold critical thinking, code generation, evaluation, and governance tasks.
- Proves mastery with auditable artifacts, peer validations, and automated control checks.

## Persona Journeys
| Persona | Primary Goal | Journey Spine | Evidence Gate |
| --- | --- | --- | --- |
| Lead Architect | Orchestrate multimodal, multi-agent platforms that comply with enterprise guardrails. | Systems runway -> Data spine -> Platform spine -> Governance runway -> Capstone defense. | Platform architecture dossier, automated eval harness, board-ready controls review. |
| Program & Product Leader | Translate AI investments into measurable portfolio outcomes. | Strategy runway -> Value instrumentation -> Delivery pipeline -> Communication studio. | Executive narrative kit, OKR telemetry, change management playbook. |
| Risk & Compliance Partner | Operationalize responsible AI across the lifecycle with traceable controls. | Policy runway -> Control libraries -> Monitoring fabric -> Assurance orchestrations. | Control attestation workspace, dynamic risk register, third-party audit simulation. |
| Automation & Agent Lead | Deploy agentic workflows safely and at scale. | Agent runway -> Workflow design -> Guardrail lab -> Integration pit -> Reliability reviews. | Agent policy stack, workflow catalog, incident mediation report. |
| Creator & Influence Partner | Amplify Academy IP, tell the story of governed AI excellence. | Narrative runway -> Editorial lab -> Distribution layer -> Community signal loop. | Campaign content kit, social telemetry, co-created insight release. |

## Program Spine
| Phase | Duration | Intent | Key Surfaces |
| --- | --- | --- | --- |
| Orientation Pulse | Week 0 | Configure assistant, benchmark skills, align with sponsor outcomes. | AI architecture maturity radar, telemetry dashboard, sponsor brief. |
| Systems Foundation | Weeks 1-4 | Establish shared mental models, responsible AI baseline, delivery patterns. | Modular micro-lessons, systems canvases, responsible AI assessments. |
| Applied Delivery | Weeks 5-16 | Run concurrent labs, ship platform components, implement evaluation fabric. | Studio labs, duo programming with assistant, control dashboards. |
| Executive Integration | Weeks 17-22 | Align strategy, finance, legal, and operations stakeholders. | Simulation workshops, portfolio reviews, executive storytelling sprints. |
| Capstone Residency | Weeks 23-26 | Deliver end-to-end architecture, operate in production-like setting. | Observation deck, automated practice audits, panel defense. |
| Lifelong Signal Loop | Post-grad | Maintain corpus updates, share research, mentor cohorts. | Knowledge graph, community orchestrations, credential renewals. |

## Track Fabric
Twelve learning galaxies provide 200+ modular experiences. Each galaxy contains three arcs (Core, Systems Studio, Leadership) that align to mastery levels. Tracks cross-link through shared deliverable schemas so assistants can recommend adjacent assets without repeating instruction.

| Galaxy Code | Title | Focus | Representative Deliverables |
| --- | --- | --- | --- |
| G0 | Launch & Telemetry Ops | Onboarding, diagnostics, instrumentation. | Persona-aligned roadmap, telemetry baselines, assistant configuration spec. |
| G1 | Vision & Strategy Orchestration | Value narratives, portfolio bets, ecosystem mapping. | AI north star doc, investment thesis, partner matrix. |
| G2 | Systems & Pattern Thinking | Systems dynamics, socio-technical lenses, architectural pattern library. | Systems map, interaction contracts, pattern decision logs. |
| G3 | Data, Knowledge & Semantics | Data governance, embeddings, knowledge graphs, semantic ops. | Data contracts, vector schemas, knowledge fabric playbook. |
| G4 | Model Engineering & Evaluation | Model lifecycle, evaluation design, quality controls. | Evaluation harness, test suites, bias mitigation plan. |
| G5 | Platform & Delivery Infrastructure | Multi-cloud infrastructure, CI/CD, observability. | Deployment blueprints, IaC repo, observability runbooks. |
| G6 | Responsible AI & Policy Integration | Regulatory alignment, control design, documentation. | Control library, policy-to-implementation trace, audit packet. |
| G7 | Agentic Workflows & Automation | Agent design, routing logic, human-in-the-loop choreography. | Agent workflow catalog, guardrail configs, incident mediation ledger. |
| G8 | Product, UX & Adoption | Product narratives, UX research, adoption accelerators. | Experience architecture, adoption telemetry, playbook for support teams. |
| G9 | Operations, Reliability & Cost | SRE for AI systems, optimization, sustainability. | Resilience strategy, cost telemetry, green AI report. |
| G10 | Executive Communication & Influence | Board communication, finance alignment, change leadership. | Executive brief, financial model, stakeholder influence map. |
| G11 | Frontier Intelligence & Innovation | Emerging research synthesis, open source ecosystems, venture bets. | Research digest, frontier experiment plan, partner scouting dossier. |

## Mastery Framework
- **Explorer**: Orients learners, ensures shared vocabulary, uses scenario-based diagnostics. Completion requires mission charter, risk inventory, orientation review.
- **Builder**: Applies patterns in labs. Blueprint: shipping at least four studio deliverables and passing automated evaluation acceptance tests.
- **Architect**: Integrates systems end-to-end. Earned by leading governance review, deploying monitored service, and publishing integration runbook.
- **Strategist**: Connects portfolio value and change orchestration. Requires executive simulation, portfolio telemetry, and adoption readiness checks.
- **Luminary**: Contributions to research and community. Requires authored insight kit, mentorship artifacts, and verifiable credential distribution.

## Timeboxing & Cadence
- Weekly pulse: research brief, risk radar, toolchain updates with citations and diff logs.
- Bi-weekly studio: guided deep work blocks instrumented with code-coach agents and evaluation bots.
- Monthly governance summit: real stakeholders (legal, risk, finance) join panel to vet controls.
- Quarterly capstone review: cross-cohort critique, upgrade rubrics, refresh telemetry models.

## Assessment & Evidence Model
- Automated scoring pipelines ingest repo tests, evaluation dashboards, compliance checklists, and UX telemetry.
- Review panels sign off on qualitative rubrics that the assistant pre-populates with citations and anomalies.
- Learners maintain a digital Evidence Locker (structured markdown + artifacts) connected to verifiable credentials.
- Skill graph updates weekly based on module completions, deliverable quality, and peer endorsements.

## Agent-Augmented Teaching Stack
1. **Scout Agent** fetches fresh research, regulatory updates, and vendor releases. Outputs annotated brief with citations and diff summary.
2. **Coach Agent** provides guided practice, tests reasoning, and enforces safe experimentation boundaries.
3. **Critic Agent** runs evaluation heuristics, red-teams outputs, and flags governance violations.
4. **Archivist Agent** tags evidence, updates knowledge graph, and generates credential payloads.
5. **Companion Agent** personalizes nudges, suggests adjacent modules, and tracks burnout signals.

## Data & Telemetry Fabric
- Unified learner graph persisted in the Academy warehouse with privacy-compliant identifiers and consent tracking.
- Module metadata schema: `id`, `galaxy`, `arc`, `level`, `persona-fit`, `modality`, `duration`, `prerequisites`, `deliverables`, `evidence-signals`, `refresh-cadence`.
- Observability stack: metrics (completion, quality, governance), traces (assistant interactions), logs (evaluation outputs), events (milestones, mentor reviews).
- Reporting surfaces: cohort cockpit, sponsor dashboards, agent API (aggregated), open community pulseboard (sanitized).

## Content Refresh Operations
- Weekly triage: new research, policy changes, vendor updates routed to relevant galaxy backlog.
- Monthly backlog grooming with subject-matter councils ensures modules stay within 90-day freshness SLAs.
- Semi-annual architecture summit re-baselines patterns, labs, and guardrails.
- Living changelog tracked in `docs/curriculum/changelog.md` with assistant-generated diff notes.

## Governance & Inclusion
- Accessibility overlays for every lab (screen reader optimized, captioned video, keyboard-first controls).
- Region-aware policy breakouts (US, EU AI Act, Singapore AI Verify, Canada AIDA pilot) with local experts.
- Inclusive datasets and casework representing healthcare, finance, public sector, and creative industries.
- Psychological safety protocols for critique sessions, including anonymized feedback and bias monitors.

## Extension Paths
- Vertical launchpads: Healthcare trust architectures, financial crime prevention, advanced manufacturing AI.
- Research guilds: foundation model safety, evaluation science, agentic orchestration, sustainability.
- Venture studio sprints with partner startups to prototype go-to-market accelerators.
- Alumni fellowship with publication stipends, open-source maintainer tracks, and mentor matching.

